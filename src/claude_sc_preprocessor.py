#!/usr/bin/env python3
"""
SuperClaude ì§€ëŠ¥í˜• í”Œë˜ê·¸ ìë™ì™„ì„± ì‹œìŠ¤í…œ (í•™ìŠµ ê¸°ëŠ¥ í†µí•©)

ì‚¬ìš©ìê°€ /sc: ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´ ORCHESTRATOR.md ë¡œì§ê³¼ í•™ìŠµëœ ë°ì´í„°ì— ë”°ë¼
ìë™ìœ¼ë¡œ ìµœì ì˜ í”Œë˜ê·¸ ì¡°í•©ì„ ì¶”ì²œí•˜ê³  ì ìš©í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import re
import json
import yaml
import os
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

# í•™ìŠµ ì‹œìŠ¤í…œ í†µí•© - ìƒˆë¡œìš´ ê²½ë¡œ êµ¬ì¡°
try:
    import sys
    from pathlib import Path
    
    # ìƒˆ êµ¬ì¡°ì—ì„œ í•™ìŠµ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
    learning_path = Path.home() / '.claude' / 'superclaude' / 'learning'
    if str(learning_path) not in sys.path:
        sys.path.insert(0, str(learning_path))
    
    from adaptive_recommender import get_personalized_recommender, PersonalizedRecommendation
    from data_collector import get_data_collector
    from feedback_processor import get_feedback_processor
    LEARNING_ENABLED = True
except ImportError:
    LEARNING_ENABLED = False
    print("Learning system not available - using static patterns only")


@dataclass
class ProjectContext:
    """í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì •ë³´"""
    project_type: str
    domain: str
    complexity: str
    file_count: int
    framework: Optional[str] = None
    language: Optional[str] = None
    

@dataclass
class FlagRecommendation:
    """í”Œë˜ê·¸ ì¶”ì²œ ê²°ê³¼"""
    flags: str
    confidence: int
    reasoning: str
    mcp_servers: List[str]
    personas: List[str]


class PatternMatcher:
    """ORCHESTRATOR.md íŒ¨í„´ ë§¤ì¹­ ì—”ì§„"""
    
    def __init__(self, rules_path: str):
        self.rules = self._load_rules(rules_path)
        self.orchestrator_patterns = self._load_orchestrator_patterns()
    
    def _load_rules(self, path: str) -> Dict:
        """ê·œì¹™ íŒŒì¼ ë¡œë“œ"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            return self._get_default_rules()
    
    def _get_default_rules(self) -> Dict:
        """ê¸°ë³¸ ê·œì¹™ ë°˜í™˜ (íŒŒì¼ì´ ì—†ì„ ë•Œ)"""
        return {
            'patterns': {
                'analyze_general': {
                    'keywords': ['analyze', 'ë¶„ì„', 'review', 'ê²€í† '],
                    'base_flags': '--persona-analyzer --think',
                    'confidence': 85,
                    'mcp_servers': ['Sequential']
                },
                'analyze_security': {
                    'keywords': ['security', 'ë³´ì•ˆ', 'vulnerability', 'ì·¨ì•½ì ', 'audit'],
                    'base_flags': '--persona-security --focus security --think --validate',
                    'confidence': 95,
                    'mcp_servers': ['Sequential']
                },
                'analyze_performance': {
                    'keywords': ['performance', 'ì„±ëŠ¥', 'optimize', 'ìµœì í™”', 'bottleneck'],
                    'base_flags': '--persona-performance --think-hard --focus performance',
                    'confidence': 90,
                    'mcp_servers': ['Sequential', 'Playwright']
                },
                'implement_ui': {
                    'keywords': ['component', 'ì»´í¬ë„ŒíŠ¸', 'ui', 'interface', 'frontend'],
                    'base_flags': '--persona-frontend --magic --c7',
                    'confidence': 94,
                    'mcp_servers': ['Magic', 'Context7']
                },
                'implement_api': {
                    'keywords': ['api', 'endpoint', 'backend', 'server', 'ì„œë²„'],
                    'base_flags': '--persona-backend --seq --c7',
                    'confidence': 92,
                    'mcp_servers': ['Sequential', 'Context7']
                },
                'improve_quality': {
                    'keywords': ['improve', 'ê°œì„ ', 'refactor', 'ë¦¬íŒ©í† ë§', 'cleanup'],
                    'base_flags': '--persona-refactorer --loop --validate',
                    'confidence': 88,
                    'mcp_servers': ['Sequential']
                }
            }
        }
    
    def _load_orchestrator_patterns(self) -> Dict:
        """ORCHESTRATOR.mdì˜ Master Routing Table íŒ¨í„´"""
        return {
            'analyze_architecture': {
                'pattern': r'(analyze|ë¶„ì„).*(architecture|ì•„í‚¤í…ì²˜)',
                'flags': '--persona-architect --ultrathink --seq',
                'confidence': 95,
                'complexity': 'complex'
            },
            'security_audit': {
                'pattern': r'(security|ë³´ì•ˆ).*(audit|ê°ì‚¬)',
                'flags': '--persona-security --ultrathink --seq --validate',
                'confidence': 95,
                'complexity': 'complex'
            },
            'implement_auth': {
                'pattern': r'(implement|êµ¬í˜„).*(auth|ì¸ì¦)',
                'flags': '--persona-security --persona-backend --validate',
                'confidence': 90,
                'complexity': 'complex'
            },
            'optimize_performance': {
                'pattern': r'(optimize|ìµœì í™”).*(performance|ì„±ëŠ¥)',
                'flags': '--persona-performance --think-hard --play',
                'confidence': 90,
                'complexity': 'complex'
            }
        }
    
    def find_best_match(self, command: str, description: str, context: ProjectContext) -> FlagRecommendation:
        """ìµœì ì˜ í”Œë˜ê·¸ ì¡°í•© ì°¾ê¸°"""
        
        # 1. ORCHESTRATOR ê³ ê¸‰ íŒ¨í„´ ìš°ì„  í™•ì¸
        full_text = f"{command} {description}".lower()
        
        for pattern_name, pattern_info in self.orchestrator_patterns.items():
            if re.search(pattern_info['pattern'], full_text, re.IGNORECASE):
                return FlagRecommendation(
                    flags=pattern_info['flags'],
                    confidence=pattern_info['confidence'],
                    reasoning=f"ORCHESTRATOR íŒ¨í„´ ë§¤ì¹­: {pattern_name}",
                    mcp_servers=self._extract_mcp_servers(pattern_info['flags']),
                    personas=self._extract_personas(pattern_info['flags'])
                )
        
        # 2. ê¸°ë³¸ ê·œì¹™ íŒ¨í„´ ë§¤ì¹­ - ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë§¤ì¹­
        best_match = None
        best_pattern_name = None
        highest_score = 0
        
        # ìš°ì„ ìˆœìœ„ íŒ¨í„´ ë¨¼ì € í™•ì¸ (ë³´ì•ˆ, ì„±ëŠ¥, ì•„í‚¤í…ì²˜ ë“±)
        priority_patterns = ['analyze_security', 'analyze_performance', 'analyze_architecture', 'implement_authentication']
        
        for pattern_name in priority_patterns:
            if pattern_name in self.rules['patterns']:
                pattern_info = self.rules['patterns'][pattern_name]
                score = self._calculate_match_score(full_text, pattern_info['keywords'])
                if score > 0:  # í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ ìµœìš°ì„ 
                    highest_score = score + 0.5  # ìš°ì„ ìˆœìœ„ ë³´ë„ˆìŠ¤
                    best_match = pattern_info
                    best_pattern_name = pattern_name
                    break
        
        # ìš°ì„ ìˆœìœ„ íŒ¨í„´ì—ì„œ ë§¤ì¹­ ì•ˆëœ ê²½ìš° ì¼ë°˜ íŒ¨í„´ í™•ì¸
        if not best_match:
            for pattern_name, pattern_info in self.rules['patterns'].items():
                score = self._calculate_match_score(full_text, pattern_info['keywords'])
                
                if score > highest_score:
                    highest_score = score
                    best_match = pattern_info
                    best_pattern_name = pattern_name
                
        if best_match and highest_score > 0.0:  # í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´
            flags = self._apply_context_modifiers(best_match['base_flags'], context)
            return FlagRecommendation(
                flags=flags,
                confidence=min(95, int(best_match['confidence'] * (0.5 + highest_score * 0.5))),
                reasoning=f"íŒ¨í„´ ë§¤ì¹­: {best_pattern_name} (ì ìˆ˜: {highest_score:.2f})",
                mcp_servers=best_match.get('mcp_servers', []),
                personas=self._extract_personas(flags)
            )
        
        # 3. ê¸°ë³¸ í´ë°±
        return self._get_default_recommendation(command, context)
    
    def _calculate_match_score(self, text: str, keywords: List[str]) -> float:
        """í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        text_lower = text.lower()
        matches = sum(1 for keyword in keywords if keyword.lower() in text_lower)
        return matches / len(keywords) if keywords else 0
    
    def _apply_context_modifiers(self, base_flags: str, context: ProjectContext) -> str:
        """í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¥¸ í”Œë˜ê·¸ ìˆ˜ì •"""
        flags = base_flags
        
        # ë³µì¡ë„ì— ë”°ë¥¸ thinking ë ˆë²¨ ì¡°ì •
        if context.complexity == 'complex' and '--think' in flags and '--think-hard' not in flags:
            flags = flags.replace('--think', '--think-hard')
        
        # í”„ë¡œì íŠ¸ íƒ€ì…ë³„ ìµœì í™”
        if context.project_type == 'python_backend':
            if '--persona-backend' not in flags and 'analyze' in flags:
                flags += ' --validate'  # Python ë°±ì—”ë“œëŠ” ì¶”ê°€ ê²€ì¦
        
        # íŒŒì¼ ìˆ˜ì— ë”°ë¥¸ delegation ì¶”ê°€
        if context.file_count > 50:
            flags += ' --delegate'
        
        # í† í° íš¨ìœ¨ì„±ì„ ìœ„í•œ ì••ì¶•
        flags += ' --uc'
        
        return flags
    
    def _extract_mcp_servers(self, flags: str) -> List[str]:
        """í”Œë˜ê·¸ì—ì„œ MCP ì„œë²„ ì¶”ì¶œ"""
        servers = []
        if '--seq' in flags or '--sequential' in flags:
            servers.append('Sequential')
        if '--c7' in flags or '--context7' in flags:
            servers.append('Context7')
        if '--magic' in flags:
            servers.append('Magic')
        if '--play' in flags or '--playwright' in flags:
            servers.append('Playwright')
        return servers
    
    def _extract_personas(self, flags: str) -> List[str]:
        """í”Œë˜ê·¸ì—ì„œ persona ì¶”ì¶œ"""
        personas = []
        persona_map = {
            '--persona-analyzer': 'analyzer',
            '--persona-architect': 'architect', 
            '--persona-security': 'security',
            '--persona-performance': 'performance',
            '--persona-frontend': 'frontend',
            '--persona-backend': 'backend',
            '--persona-refactorer': 'refactorer'
        }
        
        for flag, persona in persona_map.items():
            if flag in flags:
                personas.append(persona)
        
        return personas
    
    def _get_default_recommendation(self, command: str, context: ProjectContext) -> FlagRecommendation:
        """ê¸°ë³¸ ì¶”ì²œ (ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)"""
        if 'analyze' in command:
            flags = '--persona-analyzer --think --uc'
            confidence = 70
        elif 'implement' in command:
            if context.project_type == 'python_backend':
                flags = '--persona-backend --c7 --uc'
            else:
                flags = '--persona-frontend --magic --uc'
            confidence = 75
        elif 'improve' in command:
            flags = '--persona-refactorer --think --uc'
            confidence = 70
        else:
            flags = '--think --uc'
            confidence = 60
            
        return FlagRecommendation(
            flags=flags,
            confidence=confidence,
            reasoning="ê¸°ë³¸ ëª…ë ¹ì–´ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ",
            mcp_servers=self._extract_mcp_servers(flags),
            personas=self._extract_personas(flags)
        )


class ProjectAnalyzer:
    """í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ê¸°"""
    
    def __init__(self, project_path: str):
        self.project_path = Path(project_path)
    
    def analyze(self) -> ProjectContext:
        """í”„ë¡œì íŠ¸ ë¶„ì„"""
        
        # ì–¸ì–´ ë° í”„ë ˆì„ì›Œí¬ íƒì§€
        language, framework = self._detect_language_and_framework()
        
        # í”„ë¡œì íŠ¸ íƒ€ì… ê²°ì •
        project_type = self._determine_project_type(language, framework)
        
        # ë„ë©”ì¸ ì¶”ì •
        domain = self._estimate_domain()
        
        # ë³µì¡ë„ ê³„ì‚°
        complexity = self._calculate_complexity()
        
        # íŒŒì¼ ìˆ˜ ê³„ì‚°
        file_count = self._count_source_files()
        
        return ProjectContext(
            project_type=project_type,
            domain=domain, 
            complexity=complexity,
            file_count=file_count,
            framework=framework,
            language=language
        )
    
    def _detect_language_and_framework(self) -> Tuple[str, Optional[str]]:
        """ì–¸ì–´ ë° í”„ë ˆì„ì›Œí¬ íƒì§€"""
        
        # Python ì²´í¬
        if (self.project_path / 'pyproject.toml').exists() or \
           (self.project_path / 'requirements.txt').exists():
            
            # Python í”„ë ˆì„ì›Œí¬ ì²´í¬
            framework = None
            if (self.project_path / 'main.py').exists():
                try:
                    main_content = (self.project_path / 'main.py').read_text()
                    if 'asyncio' in main_content:
                        framework = 'asyncio'
                    elif 'flask' in main_content.lower():
                        framework = 'flask'
                    elif 'django' in main_content.lower():
                        framework = 'django'
                    elif 'fastapi' in main_content.lower():
                        framework = 'fastapi'
                except:
                    pass
            
            return 'python', framework
        
        # JavaScript/TypeScript ì²´í¬
        if (self.project_path / 'package.json').exists():
            try:
                package_json = json.loads((self.project_path / 'package.json').read_text())
                deps = {**package_json.get('dependencies', {}), 
                       **package_json.get('devDependencies', {})}
                
                if 'react' in deps:
                    return 'javascript', 'react'
                elif 'vue' in deps:
                    return 'javascript', 'vue'
                elif 'angular' in deps:
                    return 'javascript', 'angular'
                else:
                    return 'javascript', 'node'
            except:
                return 'javascript', None
        
        return 'unknown', None
    
    def _determine_project_type(self, language: str, framework: Optional[str]) -> str:
        """í”„ë¡œì íŠ¸ íƒ€ì… ê²°ì •"""
        if language == 'python':
            if framework in ['flask', 'django', 'fastapi']:
                return 'python_web'
            elif framework == 'asyncio':
                return 'python_backend'
            else:
                return 'python_general'
        elif language == 'javascript':
            if framework in ['react', 'vue', 'angular']:
                return 'frontend'
            else:
                return 'backend'
        else:
            return 'general'
    
    def _estimate_domain(self) -> str:
        """ë„ë©”ì¸ ì¶”ì •"""
        project_name = self.project_path.name.lower()
        
        if 'test' in project_name or 'eol' in project_name:
            return 'hardware_testing'
        elif 'web' in project_name or 'api' in project_name:
            return 'web_development'
        elif 'ui' in project_name or 'frontend' in project_name:
            return 'frontend'
        elif 'ml' in project_name or 'ai' in project_name:
            return 'machine_learning'
        else:
            return 'general'
    
    def _calculate_complexity(self) -> str:
        """ë³µì¡ë„ ê³„ì‚°"""
        file_count = self._count_source_files()
        
        if file_count > 100:
            return 'complex'
        elif file_count > 20:
            return 'moderate'
        else:
            return 'simple'
    
    def _count_source_files(self) -> int:
        """ì†ŒìŠ¤ íŒŒì¼ ìˆ˜ ê³„ì‚°"""
        extensions = ['.py', '.js', '.ts', '.jsx', '.tsx', '.vue', '.go', '.rs', '.java', '.cpp', '.c']
        count = 0
        
        try:
            for ext in extensions:
                count += len(list(self.project_path.rglob(f'*{ext}')))
        except:
            count = 10  # ê¸°ë³¸ê°’
            
        return count


class SCCommandProcessor:
    """SuperClaude ëª…ë ¹ì–´ ì „ì²˜ë¦¬ê¸° (í•™ìŠµ ê¸°ëŠ¥ í†µí•©)"""
    
    def __init__(self, rules_path: Optional[str] = None):
        if rules_path is None:
            rules_path = str(Path.home() / '.claude' / 'superclaude' / 'core' / 'orchestrator_rules.yaml')
        
        self.pattern_matcher = PatternMatcher(rules_path)
        self.current_dir = os.getcwd()
        
        # í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if LEARNING_ENABLED:
            self.recommender = get_personalized_recommender()
            self.data_collector = get_data_collector()
            self.feedback_processor = get_feedback_processor()
        else:
            self.recommender = None
            self.data_collector = None
            self.feedback_processor = None
        
        # í˜„ì¬ ìƒí˜¸ì‘ìš© ì¶”ì 
        self.current_interaction_id = None
        
    def process(self, user_input: str, quick_mode: bool = True) -> str:
        """ì‚¬ìš©ì ì…ë ¥ ì „ì²˜ë¦¬ (í•™ìŠµ ê¸°ëŠ¥ í¬í•¨)"""
        
        # /sc: ëª…ë ¹ì–´ê°€ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if not user_input.strip().startswith('/sc:'):
            return user_input
        
        try:
            # ëª…ë ¹ì–´ì™€ ì„¤ëª… ë¶„ë¦¬
            command, description = self._parse_sc_command(user_input)
            
            # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            context = self._get_project_context()
            
            # ë¹ ë¥¸ ëª¨ë“œ: ì¦‰ì‹œ ì‘ë‹µ ìš°ì„ 
            if quick_mode:
                try:
                    # ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ ìƒˆ ê²½ë¡œì—ì„œ import
                    perf_optimizer_path = Path.home() / '.claude' / 'superclaude' / 'learning'
                    if str(perf_optimizer_path) not in sys.path:
                        sys.path.insert(0, str(perf_optimizer_path))
                    from performance_optimizer import quick_recommend
                    quick_result = quick_recommend(user_input, command, description, context.__dict__)
                    
                    # ë¹ ë¥¸ ì¶”ì²œì„ PersonalizedRecommendation í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    recommendation = type('QuickRecommendation', (), {
                        'flags': quick_result.flags,
                        'confidence': quick_result.confidence,
                        'reasoning': [quick_result.reasoning],
                        'personalization_factors': {'quick_mode': True, 'response_time_ms': quick_result.response_time_ms},
                        'learning_confidence': 0.0,
                        'fallback_used': False,
                        'recommendation_id': f"quick_{int(time.time())}"
                    })()
                    
                except ImportError:
                    # ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ ì—†ìœ¼ë©´ ê¸°ë³¸ ì²˜ë¦¬
                    quick_mode = False
            
            # ì¼ë°˜ ëª¨ë“œ ë˜ëŠ” ë¹ ë¥¸ ëª¨ë“œ ì‹¤íŒ¨ì‹œ
            if not quick_mode:
                # í•™ìŠµ ê¸°ë°˜ ì¶”ì²œ ë˜ëŠ” ê¸°ë³¸ íŒ¨í„´ ë§¤ì¹­
                if LEARNING_ENABLED and self.recommender:
                    recommendation = self._get_learning_based_recommendation(user_input, context)
                    
                    # ìƒí˜¸ì‘ìš© ì‹œì‘ ê¸°ë¡
                    if self.data_collector:
                        self.current_interaction_id = self.data_collector.start_interaction(
                            user_input=user_input,
                            recommended_flags=recommendation.flags,
                            confidence=recommendation.confidence,
                            reasoning=', '.join(recommendation.reasoning),
                            project_context=context
                        )
                else:
                    # ê¸°ë³¸ íŒ¨í„´ ë§¤ì¹­
                    legacy_recommendation = self.pattern_matcher.find_best_match(command, description, context)
                    recommendation = self._convert_legacy_recommendation(legacy_recommendation)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            enhanced_input = self._format_enhanced_command(
                user_input, recommendation, context
            )
            
            return enhanced_input
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ì…ë ¥ ë°˜í™˜
            print(f"Warning: SCCommandProcessor error: {e}")
            return user_input
    
    def record_execution_result(self, success: bool, execution_time: float, 
                              error_details: Optional[str] = None):
        """ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡ (í•™ìŠµì„ ìœ„í•´)"""
        
        if not LEARNING_ENABLED or not self.current_interaction_id:
            return
        
        try:
            # ìƒí˜¸ì‘ìš© ì¢…ë£Œ ê¸°ë¡
            if self.data_collector:
                self.data_collector.end_interaction(
                    actual_flags="",  # ì‹¤ì œ ì‚¬ìš©ëœ í”Œë˜ê·¸ëŠ” Hookì—ì„œ ìˆ˜ì§‘
                    success=success,
                    error_message=error_details
                )
            
            # ì¦‰ì‹œ í”¼ë“œë°± ì²˜ë¦¬
            if self.feedback_processor:
                self.feedback_processor.process_immediate_feedback(
                    interaction_id=self.current_interaction_id,
                    success=success,
                    execution_time=execution_time,
                    error_details=error_details
                )
            
            self.current_interaction_id = None
            
        except Exception as e:
            print(f"Warning: Failed to record execution result: {e}")
    
    def _get_learning_based_recommendation(self, user_input: str, context: Dict) -> PersonalizedRecommendation:
        """í•™ìŠµ ê¸°ë°˜ ì¶”ì²œ ìƒì„±"""
        
        try:
            personalized_rec = self.recommender.get_personalized_recommendation(
                user_input, context
            )
            return personalized_rec
            
        except Exception as e:
            print(f"Warning: Learning recommendation failed, falling back to static: {e}")
            
            # í´ë°±: ê¸°ë³¸ íŒ¨í„´ ë§¤ì¹­
            command, description = self._parse_sc_command(user_input)
            legacy_rec = self.pattern_matcher.find_best_match(command, description, context)
            return self._convert_legacy_recommendation(legacy_rec)
    
    def _convert_legacy_recommendation(self, legacy_rec: FlagRecommendation) -> PersonalizedRecommendation:
        """ê¸°ì¡´ ì¶”ì²œì„ ìƒˆë¡œìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        
        return PersonalizedRecommendation(
            flags=legacy_rec.flags,
            confidence=legacy_rec.confidence,
            reasoning=legacy_rec.reasoning.split(', ') if legacy_rec.reasoning else [],
            personalization_factors={'legacy_mode': True},
            learning_confidence=0.0,
            fallback_used=True,
            recommendation_id=f"legacy_{int(time.time())}"
        )
    
    def _parse_sc_command(self, user_input: str) -> Tuple[str, str]:
        """SuperClaude ëª…ë ¹ì–´ íŒŒì‹±"""
        # /sc:analyze ì´ ì½”ë“œ ë¶„ì„í•´ì¤˜ -> ('analyze', 'ì´ ì½”ë“œ ë¶„ì„í•´ì¤˜')
        match = re.match(r'/sc:(\w+)\s*(.*)', user_input.strip())
        if match:
            return match.group(1), match.group(2)
        else:
            return 'unknown', user_input
    
    def _get_project_context(self) -> ProjectContext:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        analyzer = ProjectAnalyzer(self.current_dir)
        return analyzer.analyze()
    
    def _format_enhanced_command(self, original_input: str, recommendation, context) -> str:
        """í–¥ìƒëœ ëª…ë ¹ì–´ í¬ë§·íŒ… (í•™ìŠµ ê¸°ëŠ¥ ì§€ì›)"""
        
        # ì¶”ì²œ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        if hasattr(recommendation, 'personalization_factors'):
            # í•™ìŠµ ê¸°ë°˜ ì¶”ì²œ
            return self._format_learning_recommendation(original_input, recommendation, context)
        else:
            # ê¸°ì¡´ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ
            return self._format_legacy_recommendation(original_input, recommendation, context)
    
    def _format_learning_recommendation(self, original_input: str, recommendation: PersonalizedRecommendation, context) -> str:
        """í•™ìŠµ ê¸°ë°˜ ì¶”ì²œ í¬ë§·íŒ…"""
        
        # ë¹ ë¥¸ ëª¨ë“œ í™•ì¸
        is_quick_mode = recommendation.personalization_factors.get('quick_mode', False)
        response_time = recommendation.personalization_factors.get('response_time_ms', 0)
        
        # ê°œì¸í™” ì •ë³´ ì¤€ë¹„
        personalization_info = []
        if not recommendation.fallback_used and not is_quick_mode:
            if recommendation.personalization_factors.get('persona_preferences_applied'):
                personalization_info.append("ğŸ­ ê°œì¸ ì„ í˜¸ persona ì ìš©")
            if recommendation.personalization_factors.get('project_type_optimized'):
                personalization_info.append("ğŸ“ í”„ë¡œì íŠ¸ ë§ì¶¤ ìµœì í™”")
            if recommendation.learning_confidence > 0.7:
                personalization_info.append("ğŸ§  ê³ ì‹ ë¢°ë„ í•™ìŠµ ëª¨ë¸")
        
        # í•™ìŠµ ìƒíƒœ í‘œì‹œ
        if is_quick_mode:
            learning_status = f"âš¡ ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ ({response_time:.1f}ms)"
        else:
            learning_status = "ğŸ“ í•™ìŠµ ëª¨ë“œ" if not recommendation.fallback_used else "ğŸ“– ê¸°ë³¸ ëª¨ë“œ"
        
        activation_msg = f"""ğŸš€ SuperClaude AI ì‹œìŠ¤í…œ í™œì„±í™”

ğŸ“ í”„ë¡œì íŠ¸: {getattr(context, 'project_type', 'Unknown').replace('_', ' ').title()}
ğŸ—ï¸ ë„ë©”ì¸: {getattr(context, 'domain', 'General').replace('_', ' ').title()}
ğŸ“Š ë³µì¡ë„: {getattr(context, 'complexity', 'Unknown')} ({getattr(context, 'file_count', 0)}ê°œ íŒŒì¼)

{learning_status}
ğŸš€ ì ìš©ëœ í”Œë˜ê·¸: {recommendation.flags}
ğŸ¯ ì‹ ë¢°ë„: {recommendation.confidence}%"""

        if not is_quick_mode:
            activation_msg += f"\nğŸ§  í•™ìŠµ ì‹ ë¢°ë„: {int(recommendation.learning_confidence * 100)}%"
        
        activation_msg += "\n\nğŸ’¡ ì¶”ì²œ ê·¼ê±°:"
        
        for reason in recommendation.reasoning:
            activation_msg += f"\n   â€¢ {reason}"
        
        if personalization_info:
            activation_msg += f"\n\nğŸ¨ ê°œì¸í™” ì ìš©:"
            for info in personalization_info:
                activation_msg += f"\n   â€¢ {info}"
        elif is_quick_mode:
            activation_msg += f"\n\nâš¡ ë¹ ë¥¸ ì‘ë‹µ:\n   â€¢ ì¦‰ì‹œ ê¸°ë³¸ ì¶”ì²œ ì œê³µ\n   â€¢ ë°±ê·¸ë¼ìš´ë“œì—ì„œ í•™ìŠµ ê°œì„  ì§„í–‰ ì¤‘..."
        
        activation_msg += f"\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n{original_input} {recommendation.flags}"
        
        return activation_msg
    
    def _format_legacy_recommendation(self, original_input: str, recommendation: FlagRecommendation, context) -> str:
        """ê¸°ì¡´ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ í¬ë§·íŒ…"""
        
        # ê¸°ì¡´ í¬ë§· ìœ ì§€
        activation_msg = f"""ğŸ¯ SuperClaude ì§€ëŠ¥í˜• ë¶„ì„ í™œì„±í™”

ğŸ“ í”„ë¡œì íŠ¸: {getattr(context, 'project_type', 'Unknown').replace('_', ' ').title()}
ğŸ—ï¸ ë„ë©”ì¸: {getattr(context, 'domain', 'General').replace('_', ' ').title()}
ğŸ“Š ë³µì¡ë„: {getattr(context, 'complexity', 'Unknown')} ({getattr(context, 'file_count', 0)}ê°œ íŒŒì¼)

ğŸš€ ì ìš©ëœ í”Œë˜ê·¸: {recommendation.flags}
ğŸ¯ ì‹ ë¢°ë„: {recommendation.confidence}%
ğŸ’¡ ê·¼ê±°: {recommendation.reasoning}

ğŸ”§ MCP ì„œë²„: {', '.join(recommendation.mcp_servers) if recommendation.mcp_servers else 'None'}
ğŸ‘¥ ì „ë¬¸ê°€: {', '.join(recommendation.personas) if recommendation.personas else 'General'}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{original_input} {recommendation.flags}"""
        
        return activation_msg


def main():
    """ë©”ì¸ í•¨ìˆ˜ - CLI ì‹¤í–‰ìš©"""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python claude_sc_preprocessor.py '<user_input>'")
        sys.exit(1)
    
    user_input = sys.argv[1]
    processor = SCCommandProcessor()
    result = processor.process(user_input)
    
    print(result)


if __name__ == "__main__":
    main()